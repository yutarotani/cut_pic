{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'indexnet_matting.scriptshlmobilenetv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9b403157b97b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mindexnet_matting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscriptshlmobilenetv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhlmobilenetv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'indexnet_matting.scriptshlmobilenetv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from indexnet_matting.scriptshlmobilenetv2 import hlmobilenetv2\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "pathlist = Path(r\"C:\\Users\\fminyu\\Desktop\\python\\切り抜き\\indexnet_matting\\jpg\").glob('**/*.jpg')\n",
    "#myfile = 'filename.txt'\n",
    "\n",
    "path_name=[]\n",
    "for path in pathlist:\n",
    "    path_name.append(str(path.name))\n",
    "\n",
    "print(path_name)\n",
    "\n",
    "for i in range(len(path_name)):\n",
    "    image_path = path_name[i]\n",
    "    img = cv2.imread('indexnet_matting/jpg/'+path_name[i])\n",
    "    cv2.imwrite('indexnet_matting/jpg/img/'+str(path_name[i])+'.png',img)\n",
    "    img = img[...,::-1] #BGR->RGB\n",
    "    h,w,_ = img.shape\n",
    "    img = cv2.resize(img,(320,320))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
    "    model = model.to(device)\n",
    "    model.eval();\n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    input_tensor = preprocess(img)\n",
    "    input_batch = input_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)['out'][0]\n",
    "    output = output.argmax(0)\n",
    "    mask = output.byte().cpu().numpy()\n",
    "    mask = cv2.resize(mask,(w,h))\n",
    "    img = cv2.resize(img,(w,h))\n",
    "    #plt.gray()\n",
    "    #plt.figure(figsize=(20,20))\n",
    "    #plt.subplot(1,2,1)\n",
    "    #plt.imshow(img)\n",
    "    #plt.subplot(1,2,2)\n",
    "    #plt.imshow(mask);\n",
    "    \n",
    "    def gen_trimap(mask,k_size=(5,5),ite=1):\n",
    "        kernel = np.ones(k_size,np.uint8)\n",
    "        eroded = cv2.erode(mask,kernel,iterations = ite)\n",
    "        dilated = cv2.dilate(mask,kernel,iterations = ite)\n",
    "        trimap = np.full(mask.shape,128)\n",
    "        trimap[eroded >= 1] = 255\n",
    "        trimap[dilated == 0] = 0\n",
    "        return trimap\n",
    "    \n",
    "    trimap = gen_trimap(mask,k_size=(10,10),ite=5)\n",
    "    cv2.imwrite('indexnet_matting/jpg/trimap/'+str(path_name[i])+'_trimap.png',trimap)\n",
    "    #plt.figure(figsize=(20,20))\n",
    "    #plt.subplot(1,2,1)\n",
    "    #plt.imshow(img)\n",
    "    #plt.subplot(1,2,2)\n",
    "    #plt.imshow(trimap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from hlmobilenetv2 import hlmobilenetv2\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "IMG_SCALE = 1./255\n",
    "IMG_MEAN = np.array([0.485, 0.456, 0.406, 0]).reshape((1, 1, 4))\n",
    "IMG_STD = np.array([0.229, 0.224, 0.225, 1]).reshape((1, 1, 4))\n",
    "\n",
    "STRIDE = 32\n",
    "RESTORE_FROM = 'indexnet_matting.pth.tar'\n",
    "#RESTORE_FROM = './pretrained/indexnet_matting.pth.tar'\n",
    "RESULT_DIR = '../examples/mattes'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not os.path.exists(RESULT_DIR):\n",
    "    os.makedirs(RESULT_DIR)\n",
    "\n",
    "# load pretrained model\n",
    "net = hlmobilenetv2(\n",
    "        pretrained=False,\n",
    "        freeze_bn=True, \n",
    "        output_stride=STRIDE,\n",
    "        apply_aspp=True,\n",
    "        conv_operator='std_conv',\n",
    "        decoder='indexnet',\n",
    "        decoder_kernel_size=5,\n",
    "        indexnet='depthwise',\n",
    "        index_mode='m2o',\n",
    "        use_nonlinear=True,\n",
    "        use_context=True\n",
    "    )\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(RESTORE_FROM, map_location=device)\n",
    "    pretrained_dict = OrderedDict()\n",
    "    for key, value in checkpoint['state_dict'].items():\n",
    "        if 'module' in key:\n",
    "            key = key[7:]\n",
    "        pretrained_dict[key] = value\n",
    "except:\n",
    "    raise Exception('Please download the pretrained model!')\n",
    "net.load_state_dict(pretrained_dict)\n",
    "net.to(device)\n",
    "if torch.cuda.is_available():\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "# switch to eval mode\n",
    "net.eval()\n",
    "\n",
    "def read_image(x):\n",
    "    img_arr = np.array(Image.open(x))\n",
    "    return img_arr\n",
    "\n",
    "def image_alignment(x, output_stride, odd=False):\n",
    "    imsize = np.asarray(x.shape[:2], dtype=np.float)\n",
    "    if odd:\n",
    "        new_imsize = np.ceil(imsize / output_stride) * output_stride + 1\n",
    "    else:\n",
    "        new_imsize = np.ceil(imsize / output_stride) * output_stride\n",
    "    h, w = int(new_imsize[0]), int(new_imsize[1])\n",
    "\n",
    "    x1 = x[:, :, 0:3]\n",
    "    x2 = x[:, :, 3]\n",
    "    new_x1 = cv.resize(x1, dsize=(w,h), interpolation=cv.INTER_CUBIC)\n",
    "    new_x2 = cv.resize(x2, dsize=(w,h), interpolation=cv.INTER_NEAREST)\n",
    "\n",
    "    new_x2 = np.expand_dims(new_x2, axis=2)\n",
    "    new_x = np.concatenate((new_x1, new_x2), axis=2)\n",
    "\n",
    "    return new_x\n",
    "\n",
    "def inference(image_path, trimap_path):\n",
    "    with torch.no_grad():\n",
    "        image, trimap = read_image(image_path), read_image(trimap_path)\n",
    "        trimap = np.expand_dims(trimap, axis=2)\n",
    "        image = np.concatenate((image, trimap), axis=2)\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        image = image.astype('float32')\n",
    "        image = (IMG_SCALE * image - IMG_MEAN) / IMG_STD\n",
    "        image = image.astype('float32')\n",
    "\n",
    "        image = image_alignment(image, STRIDE)\n",
    "        inputs = torch.from_numpy(np.expand_dims(image.transpose(2, 0, 1), axis=0))\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # inference\n",
    "        start = time()\n",
    "        outputs = net(inputs)\n",
    "        end = time()\n",
    "\n",
    "        outputs = outputs.squeeze().cpu().numpy()\n",
    "        alpha = cv.resize(outputs, dsize=(w,h), interpolation=cv.INTER_CUBIC)\n",
    "        alpha = np.clip(alpha, 0, 1) * 255.\n",
    "        trimap = trimap.squeeze()\n",
    "        mask = np.equal(trimap, 128).astype(np.float32)\n",
    "        alpha = (1 - mask) * trimap + mask * alpha\n",
    "\n",
    "        _, image_name = os.path.split(image_path)\n",
    "        Image.fromarray(alpha.astype(np.uint8)).save(os.path.join(RESULT_DIR, image_name))\n",
    "        # Image.fromarray(alpha.astype(np.uint8)).show()\n",
    "\n",
    "        running_frame_rate = 1 * float(1 / (end - start)) # batch_size = 1\n",
    "        print('framerate: {0:.2f}Hz'.format(running_frame_rate))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = [\n",
    "        '../examples/images/beach-747750_1280_2.png',\n",
    "        '../examples/images/boy-1518482_1920_9.png',\n",
    "        '../examples/images/light-bulb-1104515_1280_3.png',\n",
    "        '../examples/images/spring-289527_1920_15.png',\n",
    "        '../examples/images/wedding-dresses-1486260_1280_3.png',\n",
    "        '../examples/images/man2.png'\n",
    "        \n",
    "    ]\n",
    "    trimap_path = [\n",
    "        '../examples/trimaps/beach-747750_1280_2.png',\n",
    "        '../examples/trimaps/boy-1518482_1920_9.png',\n",
    "        '../examples/trimaps/light-bulb-1104515_1280_3.png',\n",
    "        '../examples/trimaps/spring-289527_1920_15.png',\n",
    "        '../examples/trimaps/wedding-dresses-1486260_1280_3.png',\n",
    "        '../examples/trimaps/men.png'\n",
    "    ]\n",
    "    for image, trimap in zip(image_path, trimap_path):\n",
    "        inference(image, trimap)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
