{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下のファイルに処理を適応します。(95件)\n",
      "['0.jpg', '1.jpg', '10.jpg', '11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg', '16.jpg', '17.jpg', '18.jpg', '19.jpg', '2.jpg', '20.jpg', '21.jpg', '22.jpg', '23.jpg', '24.jpg', '25.jpg', '26.jpg', '27.jpg', '28.jpg', '29.jpg', '3.jpg', '30.jpg', '31.jpg', '32.jpg', '33.jpg', '34.jpg', '35.jpg', '36.jpg', '37.jpg', '38.jpg', '39.jpg', '4.jpg', '40.jpg', '41.jpg', '42.jpg', '43.jpg', '44.jpg', '45.jpg', '46.jpg', '47.jpg', '48.jpg', '49.jpg', '5.jpg', '50.jpg', '51.jpg', '52.jpg', '53.jpg', '54.jpg', '55.jpg', '56.jpg', '57.jpg', '58.jpg', '59.jpg', '6.jpg', '60.jpg', '61.jpg', '62.jpg', '63.jpg', '64.jpg', '65.jpg', '66.jpg', '67.jpg', '68.jpg', '69.jpg', '7.jpg', '70.jpg', '71.jpg', '72.jpg', '73.jpg', '74.jpg', '75.jpg', '76.jpg', '77.jpg', '78.jpg', '79.jpg', '8.jpg', '80.jpg', '81.jpg', '82.jpg', '83.jpg', '84.jpg', '85.jpg', '86.jpg', '87.jpg', '88.jpg', '89.jpg', '9.jpg', '90.jpg', '91.jpg', '92.jpg', '93.jpg', '94.jpg']\n",
      "\n",
      "－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－\n",
      "\n",
      "輪郭の検出処理中…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [04:48<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from hlmobilenetv2 import hlmobilenetv2\n",
    "import os\n",
    "from time import time\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "pathL = Path(\"../jpg/rootdata\").glob('**/*.jpg')\n",
    "name_dic={}\n",
    "for i,path in enumerate(pathL):\n",
    "    shutil.copy(\"../jpg/rootdata/\"+str(path.name), '../jpg/name_trans/'+str(i)+'.jpg')\n",
    "    name_dic[i]=path.name\n",
    "\n",
    "\n",
    "pathlist = Path(\"../jpg/name_trans\").glob('**/*.jpg')\n",
    "#myfile = 'filename.txt'\n",
    "\n",
    "path_name=[]\n",
    "for path in pathlist:\n",
    "    path_name.append(str(path.name))\n",
    "\n",
    "print(str(len(path_name))+'件のファイルに処理を適応します。')\n",
    "#print(path_name)\n",
    "print('\\n－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－\\n')\n",
    "print('輪郭の検出処理中…')\n",
    "for i in tqdm(range(len(path_name))):\n",
    "    image_path = path_name[i]\n",
    "    img = cv2.imread('../jpg/name_trans/'+path_name[i])\n",
    "    w_file_1='../jpg/img/'+str(path_name[i])+'.png'\n",
    "    cv2.imwrite(w_file_1.replace('.jpg',''),img)\n",
    "    img = img[...,::-1] #BGR->RGB\n",
    "    h,w,_ = img.shape\n",
    "    img = cv2.resize(img,(320,320))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
    "    model = model.to(device)\n",
    "    model.eval();\n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    input_tensor = preprocess(img)\n",
    "    input_batch = input_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)['out'][0]\n",
    "    output = output.argmax(0)\n",
    "    mask = output.byte().cpu().numpy()\n",
    "    mask = cv2.resize(mask,(w,h))\n",
    "    img = cv2.resize(img,(w,h))\n",
    "    #plt.gray()\n",
    "    #plt.figure(figsize=(20,20))\n",
    "    #plt.subplot(1,2,1)\n",
    "    #plt.imshow(img)\n",
    "    #plt.subplot(1,2,2)\n",
    "    #plt.imshow(mask);\n",
    "    \n",
    "    def gen_trimap(mask,k_size=(5,5),ite=1):\n",
    "        kernel = np.ones(k_size,np.uint8)\n",
    "        eroded = cv2.erode(mask,kernel,iterations = ite)\n",
    "        dilated = cv2.dilate(mask,kernel,iterations = ite)\n",
    "        trimap = np.full(mask.shape,128)\n",
    "        trimap[eroded >= 1] = 255\n",
    "        trimap[dilated == 0] = 0\n",
    "        return trimap\n",
    "    \n",
    "    trimap = gen_trimap(mask,k_size=(10,10),ite=5)\n",
    "    w_file_2='../jpg/trimap/'+str(path_name[i])+'.png'\n",
    "    cv2.imwrite(w_file_2.replace('.jpg',''),trimap)\n",
    "    #plt.figure(figsize=(20,20))\n",
    "    #plt.subplot(1,2,1)\n",
    "    #plt.imshow(img)\n",
    "    #plt.subplot(1,2,2)\n",
    "    #plt.imshow(trimap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－\n",
      "\n",
      "学習モデルから輪郭の細部を検出中…(95件)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████████▏                                                         | 28/95 [18:43<44:48, 40.13s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-058f901139e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrimap\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrimap_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m         \u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrimap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;31m#print(img_names)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;31m#print(trimap_names)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-058f901139e5>\u001b[0m in \u001b[0;36minference\u001b[1;34m(image_path, trimap_path)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\python\\cut_pic\\indexnet_matting\\scripts\\hlmobilenetv2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder_layer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx2_de\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder_layer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1132\u001b[1;33m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder_layer0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx0_de\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\python\\cut_pic\\indexnet_matting\\scripts\\hldecoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, l_encode, l_low, indices)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0ml_encode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_encode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml_low\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0ml_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_encode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_low\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \"\"\"\n\u001b[1;32m--> 168\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2280\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2282\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2283\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2284\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('\\n－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－\\n')\n",
    "print('学習モデルから輪郭の細部を検出中…('+str(len(path_name))+'件)')\n",
    "\n",
    "IMG_SCALE = 1./255\n",
    "IMG_MEAN = np.array([0.485, 0.456, 0.406, 0]).reshape((1, 1, 4))\n",
    "IMG_STD = np.array([0.229, 0.224, 0.225, 1]).reshape((1, 1, 4))\n",
    "\n",
    "STRIDE = 32\n",
    "RESTORE_FROM = 'indexnet_matting.pth.tar'\n",
    "#RESTORE_FROM = './pretrained/indexnet_matting.pth.tar'\n",
    "RESULT_DIR = '../jpg/mattes'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not os.path.exists(RESULT_DIR):\n",
    "    os.makedirs(RESULT_DIR)\n",
    "\n",
    "# load pretrained model\n",
    "net = hlmobilenetv2(\n",
    "        pretrained=False,\n",
    "        freeze_bn=True, \n",
    "        output_stride=STRIDE,\n",
    "        apply_aspp=True,\n",
    "        conv_operator='std_conv',\n",
    "        decoder='indexnet',\n",
    "        decoder_kernel_size=5,\n",
    "        indexnet='depthwise',\n",
    "        index_mode='m2o',\n",
    "        use_nonlinear=True,\n",
    "        use_context=True\n",
    "    )\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(RESTORE_FROM, map_location=device)\n",
    "    pretrained_dict = OrderedDict()\n",
    "    for key, value in checkpoint['state_dict'].items():\n",
    "        if 'module' in key:\n",
    "            key = key[7:]\n",
    "        pretrained_dict[key] = value\n",
    "except:\n",
    "    raise Exception('Please download the pretrained model!')\n",
    "net.load_state_dict(pretrained_dict)\n",
    "net.to(device)\n",
    "if torch.cuda.is_available():\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "# switch to eval mode\n",
    "net.eval()\n",
    "\n",
    "def read_image(x):\n",
    "    img_arr = np.array(Image.open(x))\n",
    "    return img_arr\n",
    "\n",
    "def image_alignment(x, output_stride, odd=False):\n",
    "    imsize = np.asarray(x.shape[:2], dtype=np.float)\n",
    "    if odd:\n",
    "        new_imsize = np.ceil(imsize / output_stride) * output_stride + 1\n",
    "    else:\n",
    "        new_imsize = np.ceil(imsize / output_stride) * output_stride\n",
    "    h, w = int(new_imsize[0]), int(new_imsize[1])\n",
    "\n",
    "    x1 = x[:, :, 0:3]\n",
    "    x2 = x[:, :, 3]\n",
    "    new_x1 = cv2.resize(x1, dsize=(w,h), interpolation=cv2.INTER_CUBIC)\n",
    "    new_x2 = cv2.resize(x2, dsize=(w,h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    new_x2 = np.expand_dims(new_x2, axis=2)\n",
    "    new_x = np.concatenate((new_x1, new_x2), axis=2)\n",
    "\n",
    "    return new_x\n",
    "\n",
    "def inference(image_path, trimap_path):\n",
    "    with torch.no_grad():\n",
    "        image, trimap = read_image(image_path), read_image(trimap_path)\n",
    "        trimap = np.expand_dims(trimap, axis=2)\n",
    "        image = np.concatenate((image, trimap), axis=2)\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        image = image.astype('float32')\n",
    "        image = (IMG_SCALE * image - IMG_MEAN) / IMG_STD\n",
    "        image = image.astype('float32')\n",
    "\n",
    "        image = image_alignment(image, STRIDE)\n",
    "        inputs = torch.from_numpy(np.expand_dims(image.transpose(2, 0, 1), axis=0))\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        # inference\n",
    "        start = time()\n",
    "        outputs = net(inputs)\n",
    "        end = time()\n",
    "\n",
    "        outputs = outputs.squeeze().cpu().numpy()\n",
    "        alpha = cv2.resize(outputs, dsize=(w,h), interpolation=cv2.INTER_CUBIC)\n",
    "        alpha = np.clip(alpha, 0, 1) * 255.\n",
    "        trimap = trimap.squeeze()\n",
    "        mask = np.equal(trimap, 128).astype(np.float32)\n",
    "        alpha = (1 - mask) * trimap + mask * alpha\n",
    "\n",
    "        _, image_name = os.path.split(image_path)\n",
    "        Image.fromarray(alpha.astype(np.uint8)).save(os.path.join(RESULT_DIR, image_name))\n",
    "        # Image.fromarray(alpha.astype(np.uint8)).show()\n",
    "\n",
    "        running_frame_rate = 1 * float(1 / (end - start)) # batch_size = 1\n",
    "        #print('framerate: {0:.2f}Hz'.format(running_frame_rate))\n",
    "\n",
    "pathlist_1= Path(\"../jpg/img\").glob('**/*.png')\n",
    "pathlist_2= Path(\"../jpg/trimap\").glob('**/*.png')\n",
    "\n",
    "img_names=[]\n",
    "trimap_names=[]\n",
    "for path in pathlist_1:\n",
    "    img_names.append('../jpg/img/'+str(path.name))\n",
    "for path in pathlist_2:\n",
    "    trimap_names.append('../jpg/trimap/'+str(path.name))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    image_path = img_names\n",
    "    trimap_path = trimap_names\n",
    "    \n",
    "    for image, trimap in tqdm(zip(image_path, trimap_path),total=len(image_path)):\n",
    "        inference(image, trimap)\n",
    "#print(img_names)\n",
    "#print(trimap_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlist_3= Path(\"../jpg/mattes\").glob('**/*.png')\n",
    "matte_names=[]\n",
    "for path in pathlist_3:\n",
    "    matte_names.append('../jpg/mattes/'+str(path.name))\n",
    "\n",
    "\n",
    "print('\\n－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－\\n')\n",
    "print('画像の切り抜き処理中…('+str(len(path_name))+'件)')\n",
    "for j in tqdm(range(len(img_names))):\n",
    "    img = cv2.imread(img_names[j])\n",
    "    img = img[...,::-1]\n",
    "    matte = cv2.imread(matte_names[j])\n",
    "    h,w,_ = img.shape\n",
    "    bg = np.full_like(img,255) #white background\n",
    "    \n",
    "    img = img.astype(float)\n",
    "    bg = bg.astype(float)\n",
    "    \n",
    "    matte = matte.astype(float)/255\n",
    "    img = cv2.multiply(img, matte)\n",
    "    bg = cv2.multiply(bg, 1.0 - matte)\n",
    "    outImage = cv2.add(img, bg)\n",
    "    outImage=(outImage/255)\n",
    "    Img = np.clip(outImage * 255, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    Key=int(img_names[j].replace('../jpg/img/','').replace('.png',''))\n",
    "    reN=name_dic[Key]\n",
    "    \n",
    "    plt.imsave('../jpg/結果/'+reN.replace('../jpg/img/', '').replace('.jpg', '').replace('.png', '') +'.jpg',Img)\n",
    "    #plt.imshow(Img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
